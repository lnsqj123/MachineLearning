{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKc_PArKIq6J",
        "outputId": "12e20011-ac60-4806-8f9b-f6519b50fc2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "M9OpT0e8IzvW",
        "outputId": "3425bc46-698e-4c2c-f0ca-217a6273a4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog   cat   horse truck\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3)\n",
        "        self.drop1 = nn.Dropout()\n",
        "        self.fc1 = nn.Linear(256 * 2 * 2, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.drop1(F.relu(self.conv1(x)))\n",
        "        x = self.drop1(F.relu(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.drop1(F.relu(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.drop1(F.relu(self.conv4(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "metadata": {
        "id": "tWo5_uDII6kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "ZwPzovVnI77F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(net, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G7VVgFwX7uD",
        "outputId": "6e1c5c76-6785-4f02-cb77-daea7e218673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 30, 30]           1,792\n",
            "           Dropout-2           [-1, 64, 30, 30]               0\n",
            "            Conv2d-3           [-1, 64, 28, 28]          36,928\n",
            "           Dropout-4           [-1, 64, 28, 28]               0\n",
            "         MaxPool2d-5           [-1, 64, 14, 14]               0\n",
            "            Conv2d-6          [-1, 128, 12, 12]          73,856\n",
            "           Dropout-7          [-1, 128, 12, 12]               0\n",
            "         MaxPool2d-8            [-1, 128, 6, 6]               0\n",
            "            Conv2d-9            [-1, 256, 4, 4]         295,168\n",
            "          Dropout-10            [-1, 256, 4, 4]               0\n",
            "        MaxPool2d-11            [-1, 256, 2, 2]               0\n",
            "           Linear-12                  [-1, 512]         524,800\n",
            "           Linear-13                  [-1, 512]         262,656\n",
            "           Linear-14                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 1,200,330\n",
            "Trainable params: 1,200,330\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.13\n",
            "Params size (MB): 4.58\n",
            "Estimated Total Size (MB): 6.73\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-p6w_A3I8-M",
        "outputId": "22cf70eb-ad67-4b16-9568-890a8f50dfef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.302\n",
            "[1,  4000] loss: 2.300\n",
            "[1,  6000] loss: 2.241\n",
            "[1,  8000] loss: 2.189\n",
            "[1, 10000] loss: 2.166\n",
            "[1, 12000] loss: 2.148\n",
            "[2,  2000] loss: 2.117\n",
            "[2,  4000] loss: 2.119\n",
            "[2,  6000] loss: 2.105\n",
            "[2,  8000] loss: 2.093\n",
            "[2, 10000] loss: 2.083\n",
            "[2, 12000] loss: 2.075\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        new_labels = [[0 for tt in range(10)] for t in range(4)]\n",
        "        for t in range(4):\n",
        "          new_labels[t][labels[t]] = 1\n",
        "        labels = torch.tensor(new_labels)\n",
        "        print(labels)\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        print(outputs)\n",
        "        print(labels.size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2CzuWEKTNqtI",
        "outputId": "8998b17a-d635-4f4a-be28-ae4d10f2d14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
            "tensor([[0.0982, 0.1001, 0.0977, 0.0969, 0.1007, 0.1060, 0.1019, 0.0997, 0.0977,\n",
            "         0.1011],\n",
            "        [0.0989, 0.1031, 0.0991, 0.0979, 0.0979, 0.1031, 0.0993, 0.0989, 0.0999,\n",
            "         0.1018],\n",
            "        [0.0991, 0.0994, 0.0989, 0.0982, 0.0990, 0.1049, 0.1001, 0.0983, 0.1007,\n",
            "         0.1015],\n",
            "        [0.0996, 0.1021, 0.0982, 0.0987, 0.0989, 0.1035, 0.1000, 0.0982, 0.1006,\n",
            "         0.1002]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0994, 0.1034, 0.0973, 0.0961, 0.0975, 0.1062, 0.1000, 0.0988, 0.1004,\n",
            "         0.1009],\n",
            "        [0.0974, 0.1025, 0.0983, 0.0969, 0.0986, 0.1053, 0.0996, 0.0992, 0.1001,\n",
            "         0.1022],\n",
            "        [0.0984, 0.1050, 0.0990, 0.0988, 0.0991, 0.1042, 0.0988, 0.0960, 0.1014,\n",
            "         0.0992],\n",
            "        [0.0989, 0.1021, 0.0971, 0.0988, 0.0984, 0.1042, 0.0999, 0.0977, 0.1000,\n",
            "         0.1030]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0991, 0.1014, 0.0986, 0.0963, 0.0984, 0.1037, 0.0994, 0.0964, 0.1017,\n",
            "         0.1050],\n",
            "        [0.0983, 0.1016, 0.0984, 0.0976, 0.0999, 0.1043, 0.1005, 0.0995, 0.0997,\n",
            "         0.1004],\n",
            "        [0.0988, 0.1024, 0.0972, 0.0977, 0.0971, 0.1048, 0.1015, 0.1009, 0.0982,\n",
            "         0.1014],\n",
            "        [0.0993, 0.1029, 0.0971, 0.0968, 0.0989, 0.1048, 0.0997, 0.0973, 0.1013,\n",
            "         0.1020]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
            "tensor([[0.0968, 0.1046, 0.0947, 0.0972, 0.1004, 0.1105, 0.1004, 0.0957, 0.1018,\n",
            "         0.0978],\n",
            "        [0.0998, 0.1012, 0.0992, 0.0959, 0.0993, 0.1049, 0.0995, 0.0994, 0.0979,\n",
            "         0.1030],\n",
            "        [0.0955, 0.1012, 0.0969, 0.0980, 0.1029, 0.1077, 0.1012, 0.0963, 0.0963,\n",
            "         0.1041],\n",
            "        [0.0958, 0.1036, 0.1008, 0.0964, 0.0975, 0.1064, 0.0995, 0.0985, 0.0988,\n",
            "         0.1028]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0990, 0.1012, 0.0994, 0.0971, 0.0970, 0.1040, 0.0998, 0.1007, 0.1004,\n",
            "         0.1014],\n",
            "        [0.0979, 0.1032, 0.0993, 0.0984, 0.0996, 0.1050, 0.1009, 0.0965, 0.0970,\n",
            "         0.1022],\n",
            "        [0.0982, 0.1014, 0.0998, 0.0956, 0.0982, 0.1055, 0.0993, 0.1000, 0.0998,\n",
            "         0.1021],\n",
            "        [0.0973, 0.1029, 0.0985, 0.0946, 0.1014, 0.1055, 0.1012, 0.0990, 0.0992,\n",
            "         0.1004]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0965, 0.1048, 0.0973, 0.0957, 0.0987, 0.1073, 0.0989, 0.0981, 0.1012,\n",
            "         0.1015],\n",
            "        [0.0993, 0.1014, 0.0981, 0.0965, 0.0977, 0.1045, 0.0993, 0.0994, 0.1014,\n",
            "         0.1023],\n",
            "        [0.0988, 0.0998, 0.0986, 0.0987, 0.0992, 0.1037, 0.0979, 0.1004, 0.0998,\n",
            "         0.1031],\n",
            "        [0.0979, 0.1041, 0.0977, 0.0971, 0.0997, 0.1056, 0.1006, 0.0981, 0.0981,\n",
            "         0.1011]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor([[0.1004, 0.1014, 0.0981, 0.0960, 0.1016, 0.1041, 0.0981, 0.0986, 0.1008,\n",
            "         0.1007],\n",
            "        [0.0977, 0.1022, 0.1004, 0.0984, 0.0986, 0.1043, 0.1003, 0.0987, 0.0988,\n",
            "         0.1006],\n",
            "        [0.0981, 0.1019, 0.0999, 0.0972, 0.0981, 0.1059, 0.0986, 0.1007, 0.0991,\n",
            "         0.1005],\n",
            "        [0.0985, 0.1013, 0.0983, 0.0962, 0.1014, 0.1043, 0.0994, 0.0997, 0.0992,\n",
            "         0.1017]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0977, 0.1018, 0.0997, 0.0970, 0.0998, 0.1036, 0.0999, 0.0994, 0.0990,\n",
            "         0.1021],\n",
            "        [0.0966, 0.1028, 0.0990, 0.0968, 0.0983, 0.1052, 0.0990, 0.1003, 0.0996,\n",
            "         0.1023],\n",
            "        [0.0999, 0.1010, 0.0963, 0.0971, 0.0980, 0.1049, 0.1010, 0.0996, 0.1006,\n",
            "         0.1018],\n",
            "        [0.0987, 0.1026, 0.0986, 0.0963, 0.0973, 0.1056, 0.0994, 0.0993, 0.1009,\n",
            "         0.1014]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0981, 0.1036, 0.0972, 0.0948, 0.0996, 0.1069, 0.0984, 0.0991, 0.1000,\n",
            "         0.1021],\n",
            "        [0.0961, 0.1026, 0.0989, 0.0975, 0.1038, 0.1060, 0.0994, 0.0941, 0.0999,\n",
            "         0.1016],\n",
            "        [0.0999, 0.1011, 0.0996, 0.0974, 0.0979, 0.1034, 0.1005, 0.0985, 0.0995,\n",
            "         0.1022],\n",
            "        [0.1012, 0.1022, 0.0956, 0.0962, 0.1003, 0.1044, 0.0997, 0.0997, 0.0995,\n",
            "         0.1012]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0971, 0.1007, 0.0984, 0.0987, 0.0975, 0.1056, 0.1013, 0.0984, 0.1017,\n",
            "         0.1006],\n",
            "        [0.0991, 0.1027, 0.0985, 0.0972, 0.1009, 0.1046, 0.0992, 0.0971, 0.0991,\n",
            "         0.1015],\n",
            "        [0.0957, 0.1032, 0.1001, 0.0979, 0.0994, 0.1071, 0.0995, 0.0973, 0.0980,\n",
            "         0.1019],\n",
            "        [0.0973, 0.1041, 0.0994, 0.0960, 0.0989, 0.1047, 0.0989, 0.0989, 0.1006,\n",
            "         0.1013]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
            "tensor([[0.0967, 0.1017, 0.0999, 0.0964, 0.0988, 0.1059, 0.1014, 0.0988, 0.0999,\n",
            "         0.1007],\n",
            "        [0.0979, 0.1020, 0.0991, 0.0964, 0.0995, 0.1063, 0.1010, 0.0985, 0.0971,\n",
            "         0.1021],\n",
            "        [0.0959, 0.1088, 0.0938, 0.0997, 0.1007, 0.1071, 0.0994, 0.0937, 0.0979,\n",
            "         0.1029],\n",
            "        [0.0973, 0.1022, 0.0994, 0.0993, 0.0975, 0.1044, 0.1000, 0.0977, 0.1035,\n",
            "         0.0988]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0979, 0.0996, 0.0993, 0.0976, 0.1027, 0.1034, 0.1023, 0.0966, 0.0979,\n",
            "         0.1027],\n",
            "        [0.0984, 0.1048, 0.0958, 0.0972, 0.0992, 0.1064, 0.0993, 0.0962, 0.0986,\n",
            "         0.1041],\n",
            "        [0.0990, 0.1008, 0.1000, 0.0963, 0.0985, 0.1039, 0.0998, 0.1000, 0.1002,\n",
            "         0.1016],\n",
            "        [0.0985, 0.1023, 0.0964, 0.0993, 0.0986, 0.1055, 0.0976, 0.1003, 0.0988,\n",
            "         0.1027]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0962, 0.1016, 0.0975, 0.0975, 0.0980, 0.1077, 0.0997, 0.0996, 0.1014,\n",
            "         0.1008],\n",
            "        [0.0967, 0.1048, 0.1003, 0.0985, 0.0970, 0.1053, 0.0997, 0.0981, 0.0984,\n",
            "         0.1013],\n",
            "        [0.0969, 0.1025, 0.0997, 0.0970, 0.0990, 0.1048, 0.0994, 0.0982, 0.0998,\n",
            "         0.1029],\n",
            "        [0.0991, 0.1017, 0.0987, 0.0978, 0.0977, 0.1036, 0.0986, 0.0998, 0.1003,\n",
            "         0.1027]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor([[0.0998, 0.1016, 0.0991, 0.0959, 0.0980, 0.1033, 0.0980, 0.1000, 0.1015,\n",
            "         0.1029],\n",
            "        [0.0972, 0.1008, 0.0959, 0.0975, 0.0994, 0.1044, 0.1017, 0.0985, 0.1021,\n",
            "         0.1024],\n",
            "        [0.0976, 0.1017, 0.0998, 0.0980, 0.0988, 0.1069, 0.1002, 0.0964, 0.1002,\n",
            "         0.1003],\n",
            "        [0.1010, 0.1035, 0.0973, 0.0972, 0.0957, 0.1036, 0.1002, 0.0972, 0.1011,\n",
            "         0.1032]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.1000, 0.1021, 0.0970, 0.0962, 0.0974, 0.1071, 0.1002, 0.0989, 0.1009,\n",
            "         0.1002],\n",
            "        [0.0991, 0.1024, 0.0992, 0.0972, 0.0981, 0.1054, 0.0981, 0.0982, 0.0993,\n",
            "         0.1030],\n",
            "        [0.0972, 0.1038, 0.0970, 0.0958, 0.0993, 0.1070, 0.1002, 0.0966, 0.1009,\n",
            "         0.1021],\n",
            "        [0.0994, 0.0998, 0.0999, 0.0968, 0.0995, 0.1046, 0.0997, 0.0983, 0.0998,\n",
            "         0.1022]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0985, 0.1043, 0.0994, 0.0958, 0.0996, 0.1039, 0.0993, 0.0966, 0.1006,\n",
            "         0.1021],\n",
            "        [0.0947, 0.1032, 0.0980, 0.0971, 0.1005, 0.1086, 0.0981, 0.0975, 0.0988,\n",
            "         0.1035],\n",
            "        [0.0962, 0.1061, 0.0985, 0.0982, 0.1014, 0.1062, 0.1013, 0.0976, 0.0965,\n",
            "         0.0981],\n",
            "        [0.1004, 0.1010, 0.0995, 0.0956, 0.0992, 0.1044, 0.0997, 0.0977, 0.0993,\n",
            "         0.1032]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0962, 0.1026, 0.1001, 0.0981, 0.0998, 0.1057, 0.0990, 0.0980, 0.0981,\n",
            "         0.1025],\n",
            "        [0.0994, 0.1024, 0.0956, 0.0984, 0.0994, 0.1062, 0.0977, 0.0993, 0.1000,\n",
            "         0.1017],\n",
            "        [0.0979, 0.1019, 0.0986, 0.0970, 0.0991, 0.1047, 0.0992, 0.0992, 0.0989,\n",
            "         0.1035],\n",
            "        [0.0976, 0.1003, 0.0990, 0.0969, 0.1008, 0.1045, 0.0989, 0.1006, 0.1004,\n",
            "         0.1011]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0997, 0.1023, 0.0961, 0.0957, 0.1014, 0.1016, 0.1005, 0.0988, 0.1012,\n",
            "         0.1027],\n",
            "        [0.0987, 0.0995, 0.0976, 0.0986, 0.1022, 0.1035, 0.1007, 0.0989, 0.0989,\n",
            "         0.1013],\n",
            "        [0.0980, 0.1004, 0.1014, 0.0983, 0.0981, 0.1050, 0.0992, 0.0976, 0.0994,\n",
            "         0.1026],\n",
            "        [0.1002, 0.1020, 0.0989, 0.0970, 0.0986, 0.1046, 0.0996, 0.0977, 0.0998,\n",
            "         0.1017]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0987, 0.1026, 0.1009, 0.0957, 0.0974, 0.1061, 0.0999, 0.0978, 0.1007,\n",
            "         0.1003],\n",
            "        [0.0988, 0.1013, 0.0957, 0.0973, 0.0991, 0.1062, 0.1010, 0.0998, 0.1003,\n",
            "         0.1006],\n",
            "        [0.0992, 0.1009, 0.0988, 0.0977, 0.1002, 0.1030, 0.0990, 0.0996, 0.0998,\n",
            "         0.1018],\n",
            "        [0.0972, 0.1014, 0.0986, 0.0961, 0.0988, 0.1072, 0.1024, 0.0986, 0.0986,\n",
            "         0.1010]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0978, 0.1017, 0.0997, 0.0987, 0.0995, 0.1052, 0.1003, 0.0957, 0.0993,\n",
            "         0.1021],\n",
            "        [0.0999, 0.1006, 0.0987, 0.0957, 0.0990, 0.1042, 0.1007, 0.0991, 0.1008,\n",
            "         0.1012],\n",
            "        [0.0972, 0.1042, 0.1000, 0.0960, 0.1000, 0.1031, 0.0995, 0.0968, 0.1010,\n",
            "         0.1022],\n",
            "        [0.0977, 0.1053, 0.0992, 0.0962, 0.0985, 0.1038, 0.0989, 0.0970, 0.1023,\n",
            "         0.1010]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.1005, 0.1029, 0.0980, 0.0962, 0.1017, 0.1039, 0.0989, 0.0981, 0.0989,\n",
            "         0.1009],\n",
            "        [0.0965, 0.1002, 0.1012, 0.0960, 0.0992, 0.1050, 0.1000, 0.1016, 0.0988,\n",
            "         0.1015],\n",
            "        [0.0984, 0.1014, 0.0986, 0.0968, 0.0982, 0.1064, 0.0986, 0.0991, 0.0993,\n",
            "         0.1032],\n",
            "        [0.0992, 0.1018, 0.0995, 0.0976, 0.0985, 0.1042, 0.0991, 0.0974, 0.0999,\n",
            "         0.1029]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0969, 0.1005, 0.0959, 0.0959, 0.1020, 0.1042, 0.1017, 0.1005, 0.0979,\n",
            "         0.1044],\n",
            "        [0.0971, 0.1034, 0.0973, 0.0975, 0.1003, 0.1052, 0.1005, 0.0973, 0.0996,\n",
            "         0.1019],\n",
            "        [0.0984, 0.1016, 0.0999, 0.0968, 0.0988, 0.1025, 0.0994, 0.0993, 0.1001,\n",
            "         0.1033],\n",
            "        [0.0977, 0.1023, 0.0986, 0.0971, 0.0976, 0.1047, 0.1014, 0.0996, 0.1000,\n",
            "         0.1010]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0985, 0.1021, 0.0988, 0.0958, 0.0964, 0.1063, 0.0994, 0.0998, 0.1001,\n",
            "         0.1028],\n",
            "        [0.0995, 0.0994, 0.0984, 0.0960, 0.0987, 0.1030, 0.1020, 0.0993, 0.0993,\n",
            "         0.1043],\n",
            "        [0.1007, 0.1015, 0.0973, 0.0966, 0.1007, 0.1048, 0.0989, 0.0979, 0.0993,\n",
            "         0.1024],\n",
            "        [0.0980, 0.1061, 0.0961, 0.0975, 0.0972, 0.1041, 0.1001, 0.0986, 0.1022,\n",
            "         0.1001]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0973, 0.1047, 0.0972, 0.0974, 0.0981, 0.1048, 0.0990, 0.0995, 0.1004,\n",
            "         0.1016],\n",
            "        [0.0967, 0.1037, 0.0988, 0.0982, 0.0969, 0.1045, 0.0981, 0.0966, 0.1033,\n",
            "         0.1033],\n",
            "        [0.0977, 0.1023, 0.0991, 0.0996, 0.0969, 0.1058, 0.0980, 0.0986, 0.1009,\n",
            "         0.1009],\n",
            "        [0.0974, 0.1036, 0.1004, 0.0981, 0.0980, 0.1049, 0.0996, 0.0977, 0.0991,\n",
            "         0.1011]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0967, 0.1015, 0.0991, 0.0979, 0.1022, 0.1059, 0.0980, 0.0970, 0.0994,\n",
            "         0.1023],\n",
            "        [0.0981, 0.1023, 0.0976, 0.0987, 0.0998, 0.1058, 0.0987, 0.0970, 0.0990,\n",
            "         0.1030],\n",
            "        [0.0972, 0.1053, 0.0998, 0.0966, 0.1029, 0.1046, 0.1012, 0.0935, 0.0980,\n",
            "         0.1007],\n",
            "        [0.0968, 0.1038, 0.0989, 0.0976, 0.0987, 0.1063, 0.0993, 0.0980, 0.1009,\n",
            "         0.0998]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0983, 0.1024, 0.0993, 0.0990, 0.0977, 0.1039, 0.0972, 0.0995, 0.0999,\n",
            "         0.1030],\n",
            "        [0.0977, 0.1026, 0.0982, 0.0974, 0.0993, 0.1017, 0.1016, 0.1005, 0.0995,\n",
            "         0.1016],\n",
            "        [0.0983, 0.1008, 0.0984, 0.0974, 0.1008, 0.1053, 0.1002, 0.0985, 0.0996,\n",
            "         0.1007],\n",
            "        [0.0994, 0.1024, 0.0974, 0.0985, 0.0967, 0.1027, 0.0980, 0.0997, 0.1027,\n",
            "         0.1026]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0993, 0.1059, 0.0990, 0.0984, 0.0974, 0.1058, 0.0980, 0.0962, 0.0997,\n",
            "         0.1003],\n",
            "        [0.0955, 0.1008, 0.0992, 0.0991, 0.0994, 0.1042, 0.1029, 0.0990, 0.0994,\n",
            "         0.1005],\n",
            "        [0.0972, 0.1020, 0.0976, 0.0971, 0.0988, 0.1061, 0.0996, 0.0996, 0.1008,\n",
            "         0.1013],\n",
            "        [0.0973, 0.1026, 0.0961, 0.0962, 0.0998, 0.1078, 0.0995, 0.0988, 0.1012,\n",
            "         0.1007]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0980, 0.1038, 0.0981, 0.0964, 0.1008, 0.1043, 0.0987, 0.0982, 0.0986,\n",
            "         0.1031],\n",
            "        [0.0981, 0.1012, 0.0986, 0.0980, 0.0985, 0.1035, 0.0992, 0.0993, 0.1023,\n",
            "         0.1013],\n",
            "        [0.0991, 0.1012, 0.0987, 0.0975, 0.0982, 0.1035, 0.0995, 0.0996, 0.0997,\n",
            "         0.1030],\n",
            "        [0.0969, 0.1039, 0.0938, 0.0986, 0.1004, 0.1029, 0.0984, 0.0969, 0.1032,\n",
            "         0.1049]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0989, 0.1014, 0.0998, 0.0967, 0.0995, 0.1054, 0.1008, 0.0963, 0.0977,\n",
            "         0.1036],\n",
            "        [0.0974, 0.1033, 0.0967, 0.0971, 0.0987, 0.1077, 0.1010, 0.0977, 0.1012,\n",
            "         0.0992],\n",
            "        [0.0972, 0.1000, 0.0972, 0.0970, 0.0985, 0.1078, 0.1003, 0.0996, 0.1025,\n",
            "         0.0999],\n",
            "        [0.0980, 0.1018, 0.0985, 0.0980, 0.1004, 0.1021, 0.1019, 0.0991, 0.0981,\n",
            "         0.1022]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor([[0.0981, 0.1031, 0.0967, 0.0954, 0.1004, 0.1069, 0.0980, 0.0998, 0.0992,\n",
            "         0.1023],\n",
            "        [0.0998, 0.1003, 0.1001, 0.0971, 0.0987, 0.1029, 0.0992, 0.0997, 0.1002,\n",
            "         0.1020],\n",
            "        [0.0981, 0.1016, 0.0952, 0.1017, 0.1005, 0.1038, 0.0998, 0.0944, 0.1035,\n",
            "         0.1014],\n",
            "        [0.0986, 0.1012, 0.0983, 0.0979, 0.1005, 0.1050, 0.0993, 0.0983, 0.0991,\n",
            "         0.1018]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0989, 0.1021, 0.0982, 0.0962, 0.0981, 0.1047, 0.0995, 0.0998, 0.1010,\n",
            "         0.1016],\n",
            "        [0.0966, 0.1028, 0.0976, 0.0967, 0.0998, 0.1042, 0.1005, 0.0977, 0.0999,\n",
            "         0.1041],\n",
            "        [0.0983, 0.1028, 0.0987, 0.0971, 0.0995, 0.1045, 0.0986, 0.0995, 0.0998,\n",
            "         0.1013],\n",
            "        [0.0988, 0.1018, 0.0980, 0.0962, 0.0987, 0.1071, 0.1010, 0.0971, 0.1012,\n",
            "         0.1001]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0997, 0.1018, 0.0968, 0.0985, 0.1019, 0.1012, 0.1019, 0.0950, 0.1015,\n",
            "         0.1017],\n",
            "        [0.0978, 0.1014, 0.1001, 0.0973, 0.0980, 0.1051, 0.0989, 0.1005, 0.0999,\n",
            "         0.1009],\n",
            "        [0.0977, 0.1007, 0.0985, 0.0975, 0.0980, 0.1049, 0.0997, 0.1005, 0.1004,\n",
            "         0.1021],\n",
            "        [0.0976, 0.0999, 0.0997, 0.0973, 0.0992, 0.1072, 0.0977, 0.0990, 0.0998,\n",
            "         0.1027]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0991, 0.1012, 0.0985, 0.0959, 0.1004, 0.1052, 0.1013, 0.0968, 0.0994,\n",
            "         0.1022],\n",
            "        [0.1007, 0.1016, 0.0976, 0.0961, 0.1006, 0.1028, 0.0989, 0.0985, 0.1000,\n",
            "         0.1031],\n",
            "        [0.0978, 0.1020, 0.0984, 0.0982, 0.0986, 0.1067, 0.1003, 0.0979, 0.1002,\n",
            "         0.1000],\n",
            "        [0.0970, 0.1021, 0.0973, 0.0993, 0.0989, 0.1048, 0.0981, 0.0985, 0.1030,\n",
            "         0.1010]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0985, 0.1020, 0.0988, 0.0977, 0.0990, 0.1028, 0.0987, 0.0987, 0.1016,\n",
            "         0.1023],\n",
            "        [0.0986, 0.1030, 0.0970, 0.0974, 0.0993, 0.1055, 0.0993, 0.0980, 0.0991,\n",
            "         0.1029],\n",
            "        [0.0989, 0.1003, 0.0979, 0.0973, 0.1001, 0.1069, 0.0999, 0.0972, 0.0985,\n",
            "         0.1030],\n",
            "        [0.0995, 0.1017, 0.0974, 0.0959, 0.0996, 0.1062, 0.0995, 0.0982, 0.0986,\n",
            "         0.1033]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
            "tensor([[0.0988, 0.1018, 0.0974, 0.0968, 0.0995, 0.1040, 0.1015, 0.0973, 0.1007,\n",
            "         0.1023],\n",
            "        [0.0993, 0.1008, 0.0974, 0.0981, 0.0977, 0.1033, 0.1002, 0.0991, 0.1018,\n",
            "         0.1021],\n",
            "        [0.0991, 0.1031, 0.0983, 0.0980, 0.0982, 0.1057, 0.0973, 0.0995, 0.0996,\n",
            "         0.1011],\n",
            "        [0.0978, 0.1027, 0.0976, 0.0965, 0.1005, 0.1016, 0.1007, 0.0991, 0.0995,\n",
            "         0.1039]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor([[0.0982, 0.1028, 0.0998, 0.0979, 0.0994, 0.1048, 0.1002, 0.0984, 0.0989,\n",
            "         0.0997],\n",
            "        [0.0971, 0.1045, 0.0989, 0.0976, 0.0967, 0.1061, 0.0994, 0.0981, 0.0990,\n",
            "         0.1025],\n",
            "        [0.0994, 0.1027, 0.0981, 0.0959, 0.0980, 0.1062, 0.1017, 0.0995, 0.0977,\n",
            "         0.1007],\n",
            "        [0.0983, 0.1024, 0.1000, 0.0975, 0.0981, 0.1029, 0.0978, 0.0982, 0.1011,\n",
            "         0.1038]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0981, 0.1016, 0.0999, 0.0967, 0.1005, 0.1049, 0.0981, 0.0976, 0.1004,\n",
            "         0.1022],\n",
            "        [0.0981, 0.1016, 0.0985, 0.0971, 0.0992, 0.1057, 0.0996, 0.1002, 0.0993,\n",
            "         0.1008],\n",
            "        [0.0975, 0.1043, 0.0964, 0.0985, 0.0998, 0.1048, 0.0997, 0.0977, 0.0991,\n",
            "         0.1022],\n",
            "        [0.0987, 0.1010, 0.0991, 0.0977, 0.0987, 0.1053, 0.0998, 0.0985, 0.1004,\n",
            "         0.1009]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0981, 0.1029, 0.0990, 0.0972, 0.0980, 0.1054, 0.0999, 0.0990, 0.0993,\n",
            "         0.1013],\n",
            "        [0.1008, 0.0996, 0.0969, 0.0969, 0.1001, 0.1082, 0.0971, 0.0981, 0.0984,\n",
            "         0.1039],\n",
            "        [0.0986, 0.1023, 0.0980, 0.0972, 0.0994, 0.1029, 0.0996, 0.0975, 0.1022,\n",
            "         0.1021],\n",
            "        [0.0957, 0.1052, 0.0978, 0.0970, 0.0996, 0.1080, 0.0981, 0.0963, 0.1010,\n",
            "         0.1012]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0983, 0.1015, 0.0991, 0.0971, 0.0999, 0.1038, 0.1014, 0.0986, 0.1002,\n",
            "         0.1000],\n",
            "        [0.0959, 0.1030, 0.0960, 0.0979, 0.0987, 0.1068, 0.1000, 0.0987, 0.1022,\n",
            "         0.1009],\n",
            "        [0.0970, 0.1019, 0.0996, 0.0968, 0.0977, 0.1081, 0.1006, 0.0986, 0.0980,\n",
            "         0.1017],\n",
            "        [0.0995, 0.1013, 0.0993, 0.0953, 0.0995, 0.1047, 0.0997, 0.0993, 0.0990,\n",
            "         0.1024]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0985, 0.1025, 0.0966, 0.0973, 0.1014, 0.1071, 0.1012, 0.0942, 0.0984,\n",
            "         0.1028],\n",
            "        [0.1000, 0.1009, 0.0990, 0.0951, 0.1016, 0.1043, 0.1007, 0.0993, 0.0980,\n",
            "         0.1011],\n",
            "        [0.0987, 0.1033, 0.0976, 0.0963, 0.0988, 0.1053, 0.0990, 0.0981, 0.1007,\n",
            "         0.1024],\n",
            "        [0.0984, 0.1059, 0.0944, 0.0988, 0.1001, 0.1044, 0.0994, 0.0955, 0.1009,\n",
            "         0.1021]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor([[0.0977, 0.1033, 0.0990, 0.0968, 0.0995, 0.1029, 0.1002, 0.0963, 0.1014,\n",
            "         0.1028],\n",
            "        [0.0959, 0.1035, 0.0976, 0.0967, 0.1013, 0.1072, 0.0993, 0.0973, 0.0992,\n",
            "         0.1020],\n",
            "        [0.0972, 0.1024, 0.0992, 0.0975, 0.0985, 0.1064, 0.0982, 0.0989, 0.0975,\n",
            "         0.1042],\n",
            "        [0.0980, 0.1015, 0.0981, 0.0965, 0.0985, 0.1042, 0.0988, 0.0990, 0.1020,\n",
            "         0.1034]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor([[0.0991, 0.1016, 0.0996, 0.0941, 0.0987, 0.1038, 0.1007, 0.0987, 0.1018,\n",
            "         0.1018],\n",
            "        [0.0966, 0.1018, 0.0988, 0.0970, 0.0988, 0.1043, 0.1009, 0.1011, 0.0999,\n",
            "         0.1008],\n",
            "        [0.0976, 0.1023, 0.0990, 0.0971, 0.0990, 0.1036, 0.1014, 0.0984, 0.1003,\n",
            "         0.1013],\n",
            "        [0.0988, 0.1024, 0.0963, 0.0959, 0.1025, 0.1027, 0.1015, 0.0975, 0.0979,\n",
            "         0.1045]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0988, 0.1016, 0.0993, 0.0981, 0.0987, 0.1043, 0.0984, 0.0988, 0.1010,\n",
            "         0.1011],\n",
            "        [0.0969, 0.1041, 0.0939, 0.0997, 0.1013, 0.1069, 0.0972, 0.0945, 0.1031,\n",
            "         0.1024],\n",
            "        [0.0979, 0.1038, 0.0997, 0.0950, 0.0995, 0.1051, 0.0994, 0.0974, 0.0989,\n",
            "         0.1034],\n",
            "        [0.0991, 0.1006, 0.1008, 0.0970, 0.0974, 0.1036, 0.1003, 0.0999, 0.1001,\n",
            "         0.1012]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
            "tensor([[0.0996, 0.1030, 0.0979, 0.0958, 0.0966, 0.1044, 0.0994, 0.1009, 0.1008,\n",
            "         0.1017],\n",
            "        [0.0973, 0.1023, 0.0971, 0.0966, 0.1035, 0.1050, 0.0975, 0.1000, 0.0964,\n",
            "         0.1043],\n",
            "        [0.0984, 0.1019, 0.0987, 0.0949, 0.1010, 0.1038, 0.0990, 0.0991, 0.1000,\n",
            "         0.1032],\n",
            "        [0.0982, 0.0996, 0.1006, 0.0970, 0.0992, 0.1069, 0.0981, 0.0999, 0.1012,\n",
            "         0.0993]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0982, 0.1041, 0.0993, 0.0965, 0.0989, 0.1054, 0.0992, 0.0953, 0.1007,\n",
            "         0.1023],\n",
            "        [0.0986, 0.1020, 0.0974, 0.0981, 0.1009, 0.1055, 0.0965, 0.0993, 0.0997,\n",
            "         0.1020],\n",
            "        [0.0954, 0.1049, 0.0941, 0.0924, 0.1006, 0.1061, 0.1029, 0.1003, 0.1022,\n",
            "         0.1010],\n",
            "        [0.0964, 0.1047, 0.0954, 0.0977, 0.1005, 0.1061, 0.1016, 0.0965, 0.0983,\n",
            "         0.1028]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0999, 0.1016, 0.0969, 0.0962, 0.1001, 0.1050, 0.0985, 0.0977, 0.1014,\n",
            "         0.1026],\n",
            "        [0.0978, 0.1023, 0.0975, 0.0956, 0.1001, 0.1039, 0.0996, 0.0996, 0.1012,\n",
            "         0.1024],\n",
            "        [0.0975, 0.1042, 0.0965, 0.0974, 0.0978, 0.1061, 0.0986, 0.0972, 0.1014,\n",
            "         0.1032],\n",
            "        [0.0966, 0.1048, 0.0935, 0.0974, 0.1004, 0.1094, 0.1007, 0.0972, 0.1005,\n",
            "         0.0996]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0975, 0.1025, 0.0980, 0.0964, 0.0999, 0.1032, 0.1008, 0.0982, 0.1000,\n",
            "         0.1035],\n",
            "        [0.0983, 0.1004, 0.1001, 0.0973, 0.0985, 0.1044, 0.0990, 0.0995, 0.1005,\n",
            "         0.1019],\n",
            "        [0.0949, 0.1059, 0.0954, 0.0963, 0.1023, 0.1068, 0.0977, 0.0966, 0.1005,\n",
            "         0.1036],\n",
            "        [0.0992, 0.1031, 0.0989, 0.0977, 0.0981, 0.1022, 0.1001, 0.1000, 0.1002,\n",
            "         0.1005]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0954, 0.1054, 0.0975, 0.0950, 0.1012, 0.1054, 0.0993, 0.0991, 0.0986,\n",
            "         0.1032],\n",
            "        [0.0986, 0.1029, 0.0974, 0.0981, 0.0999, 0.1034, 0.0978, 0.0990, 0.1006,\n",
            "         0.1024],\n",
            "        [0.0970, 0.1054, 0.0942, 0.0972, 0.1012, 0.1045, 0.1037, 0.0949, 0.0998,\n",
            "         0.1022],\n",
            "        [0.1014, 0.1022, 0.0971, 0.0954, 0.0977, 0.1056, 0.1003, 0.0977, 0.1003,\n",
            "         0.1024]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0988, 0.1009, 0.0977, 0.0961, 0.1007, 0.1056, 0.0998, 0.0967, 0.1005,\n",
            "         0.1033],\n",
            "        [0.0972, 0.1019, 0.0968, 0.0984, 0.1011, 0.1037, 0.1016, 0.0990, 0.0996,\n",
            "         0.1009],\n",
            "        [0.0989, 0.1026, 0.0988, 0.0966, 0.0993, 0.1031, 0.0990, 0.0980, 0.1001,\n",
            "         0.1036],\n",
            "        [0.0973, 0.1032, 0.0983, 0.0948, 0.0970, 0.1070, 0.0994, 0.0995, 0.0995,\n",
            "         0.1040]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.1000, 0.1018, 0.0982, 0.0986, 0.0975, 0.1035, 0.0985, 0.0982, 0.1017,\n",
            "         0.1021],\n",
            "        [0.0984, 0.1040, 0.0964, 0.0959, 0.1006, 0.1042, 0.0993, 0.0989, 0.0997,\n",
            "         0.1026],\n",
            "        [0.0964, 0.1017, 0.0992, 0.0982, 0.1007, 0.1050, 0.0990, 0.0985, 0.0991,\n",
            "         0.1023],\n",
            "        [0.0966, 0.1032, 0.0989, 0.0987, 0.0982, 0.1044, 0.0998, 0.0988, 0.0996,\n",
            "         0.1017]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0972, 0.1020, 0.0998, 0.0972, 0.0996, 0.1052, 0.0986, 0.0982, 0.0991,\n",
            "         0.1031],\n",
            "        [0.0960, 0.1024, 0.0983, 0.0973, 0.1001, 0.1069, 0.1000, 0.0984, 0.0986,\n",
            "         0.1019],\n",
            "        [0.0964, 0.1029, 0.0965, 0.0981, 0.0997, 0.1062, 0.0985, 0.1005, 0.0994,\n",
            "         0.1017],\n",
            "        [0.0988, 0.1033, 0.0981, 0.0970, 0.0984, 0.1049, 0.0991, 0.0971, 0.1006,\n",
            "         0.1027]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0968, 0.1049, 0.0949, 0.0966, 0.1010, 0.1072, 0.0979, 0.0969, 0.0982,\n",
            "         0.1056],\n",
            "        [0.0992, 0.1007, 0.0982, 0.0958, 0.0998, 0.1038, 0.0985, 0.1007, 0.0999,\n",
            "         0.1032],\n",
            "        [0.0970, 0.1031, 0.0968, 0.0976, 0.1013, 0.1068, 0.1009, 0.0973, 0.1006,\n",
            "         0.0986],\n",
            "        [0.0958, 0.1021, 0.0981, 0.0977, 0.0967, 0.1061, 0.1017, 0.0997, 0.1006,\n",
            "         0.1015]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0985, 0.1033, 0.0976, 0.0958, 0.1003, 0.1049, 0.0995, 0.0983, 0.1007,\n",
            "         0.1010],\n",
            "        [0.0984, 0.1033, 0.0959, 0.0959, 0.0994, 0.1066, 0.0992, 0.0998, 0.0978,\n",
            "         0.1036],\n",
            "        [0.1013, 0.1010, 0.0996, 0.0967, 0.0990, 0.1029, 0.0989, 0.0982, 0.1003,\n",
            "         0.1021],\n",
            "        [0.1006, 0.1003, 0.0956, 0.0962, 0.1022, 0.1019, 0.0986, 0.1009, 0.1011,\n",
            "         0.1026]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0970, 0.1022, 0.1001, 0.0964, 0.0995, 0.1055, 0.0994, 0.0987, 0.0994,\n",
            "         0.1017],\n",
            "        [0.0974, 0.1004, 0.1003, 0.0972, 0.0989, 0.1034, 0.1006, 0.0998, 0.0995,\n",
            "         0.1027],\n",
            "        [0.0980, 0.1039, 0.0955, 0.0987, 0.0961, 0.1052, 0.1006, 0.0978, 0.1006,\n",
            "         0.1036],\n",
            "        [0.0976, 0.1027, 0.0987, 0.0986, 0.0979, 0.1038, 0.0992, 0.0978, 0.1013,\n",
            "         0.1026]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0998, 0.0998, 0.1002, 0.0955, 0.0998, 0.1055, 0.1007, 0.0970, 0.0986,\n",
            "         0.1031],\n",
            "        [0.0957, 0.1017, 0.0993, 0.0974, 0.1026, 0.1054, 0.1014, 0.0988, 0.0982,\n",
            "         0.0995],\n",
            "        [0.0978, 0.1021, 0.0985, 0.0965, 0.0986, 0.1077, 0.1002, 0.0967, 0.0993,\n",
            "         0.1027],\n",
            "        [0.0945, 0.1026, 0.0973, 0.0990, 0.1014, 0.1056, 0.0999, 0.0988, 0.0979,\n",
            "         0.1028]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0991, 0.1021, 0.0979, 0.0960, 0.0995, 0.1037, 0.1013, 0.0976, 0.1008,\n",
            "         0.1020],\n",
            "        [0.0973, 0.1029, 0.0962, 0.0958, 0.1005, 0.1088, 0.0982, 0.0961, 0.1031,\n",
            "         0.1013],\n",
            "        [0.0978, 0.1013, 0.0998, 0.0971, 0.0976, 0.1054, 0.0994, 0.1001, 0.1007,\n",
            "         0.1008],\n",
            "        [0.0982, 0.1008, 0.0995, 0.0977, 0.0985, 0.1053, 0.0997, 0.0999, 0.0988,\n",
            "         0.1017]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor([[0.0988, 0.1040, 0.0993, 0.0960, 0.0980, 0.1041, 0.0979, 0.0983, 0.0999,\n",
            "         0.1038],\n",
            "        [0.1004, 0.1043, 0.0986, 0.0976, 0.0987, 0.1029, 0.0978, 0.0973, 0.0991,\n",
            "         0.1032],\n",
            "        [0.0984, 0.0993, 0.0973, 0.0975, 0.0999, 0.1042, 0.1007, 0.1011, 0.0989,\n",
            "         0.1028],\n",
            "        [0.0976, 0.1017, 0.0941, 0.0964, 0.1030, 0.1063, 0.0991, 0.0980, 0.1010,\n",
            "         0.1028]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
            "tensor([[0.0980, 0.1040, 0.0982, 0.0982, 0.0972, 0.1053, 0.0977, 0.0989, 0.1002,\n",
            "         0.1022],\n",
            "        [0.0984, 0.1022, 0.0998, 0.0963, 0.0978, 0.1047, 0.0997, 0.0985, 0.0985,\n",
            "         0.1040],\n",
            "        [0.0986, 0.1017, 0.0966, 0.0963, 0.0997, 0.1032, 0.1009, 0.1003, 0.1004,\n",
            "         0.1022],\n",
            "        [0.0941, 0.1028, 0.0967, 0.0975, 0.1024, 0.1049, 0.1022, 0.0970, 0.0996,\n",
            "         0.1029]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0973, 0.1041, 0.0975, 0.0975, 0.0992, 0.1057, 0.0987, 0.0977, 0.0990,\n",
            "         0.1032],\n",
            "        [0.0978, 0.1012, 0.0966, 0.0959, 0.1014, 0.1046, 0.1002, 0.0996, 0.1001,\n",
            "         0.1026],\n",
            "        [0.0914, 0.1041, 0.0954, 0.0983, 0.0993, 0.1080, 0.1005, 0.0972, 0.0994,\n",
            "         0.1065],\n",
            "        [0.0957, 0.1024, 0.1009, 0.0966, 0.0980, 0.1043, 0.1016, 0.0971, 0.1022,\n",
            "         0.1011]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0987, 0.1028, 0.0979, 0.0972, 0.0987, 0.1074, 0.0989, 0.0967, 0.1000,\n",
            "         0.1017],\n",
            "        [0.0980, 0.1011, 0.0997, 0.0961, 0.0989, 0.1051, 0.0991, 0.1009, 0.0998,\n",
            "         0.1014],\n",
            "        [0.0991, 0.1008, 0.0990, 0.0960, 0.0998, 0.1041, 0.1002, 0.0984, 0.1015,\n",
            "         0.1012],\n",
            "        [0.0982, 0.1011, 0.0996, 0.0966, 0.0986, 0.1037, 0.0988, 0.1002, 0.1005,\n",
            "         0.1026]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0965, 0.1014, 0.0965, 0.0951, 0.1000, 0.1071, 0.1004, 0.0998, 0.0989,\n",
            "         0.1044],\n",
            "        [0.1016, 0.1023, 0.0964, 0.0945, 0.1010, 0.1022, 0.1010, 0.1006, 0.0989,\n",
            "         0.1015],\n",
            "        [0.0981, 0.1059, 0.0961, 0.0968, 0.1032, 0.1028, 0.0978, 0.0957, 0.1014,\n",
            "         0.1023],\n",
            "        [0.0979, 0.1011, 0.0966, 0.0996, 0.1009, 0.1039, 0.0995, 0.0979, 0.1014,\n",
            "         0.1011]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0964, 0.1022, 0.0969, 0.0977, 0.0997, 0.1060, 0.1004, 0.0998, 0.0993,\n",
            "         0.1015],\n",
            "        [0.0983, 0.1020, 0.0990, 0.0966, 0.0984, 0.1060, 0.0987, 0.0986, 0.1003,\n",
            "         0.1022],\n",
            "        [0.1000, 0.1009, 0.0970, 0.0959, 0.1008, 0.1047, 0.0989, 0.0986, 0.1021,\n",
            "         0.1010],\n",
            "        [0.0963, 0.1039, 0.0984, 0.0961, 0.0980, 0.1079, 0.0996, 0.0993, 0.0981,\n",
            "         0.1024]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0974, 0.1025, 0.0994, 0.0962, 0.0988, 0.1054, 0.0999, 0.0995, 0.0990,\n",
            "         0.1020],\n",
            "        [0.0963, 0.1032, 0.0978, 0.0971, 0.0975, 0.1041, 0.0992, 0.0987, 0.1024,\n",
            "         0.1037],\n",
            "        [0.0998, 0.1015, 0.0987, 0.0961, 0.0987, 0.1032, 0.0998, 0.0991, 0.0992,\n",
            "         0.1037],\n",
            "        [0.0945, 0.1065, 0.0943, 0.0971, 0.1007, 0.1084, 0.1006, 0.0969, 0.0975,\n",
            "         0.1034]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0986, 0.1007, 0.0993, 0.0964, 0.0998, 0.1040, 0.1002, 0.0981, 0.0999,\n",
            "         0.1031],\n",
            "        [0.0964, 0.1030, 0.0974, 0.0976, 0.0991, 0.1071, 0.1006, 0.0963, 0.1009,\n",
            "         0.1016],\n",
            "        [0.0998, 0.1015, 0.0990, 0.0973, 0.0979, 0.1031, 0.1004, 0.0985, 0.1010,\n",
            "         0.1015],\n",
            "        [0.0974, 0.1018, 0.0985, 0.0979, 0.0991, 0.1050, 0.0994, 0.0998, 0.0990,\n",
            "         0.1021]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0950, 0.1081, 0.0958, 0.0959, 0.1024, 0.1076, 0.0996, 0.0965, 0.1002,\n",
            "         0.0987],\n",
            "        [0.1006, 0.1030, 0.0973, 0.0974, 0.0976, 0.1030, 0.0984, 0.0996, 0.1014,\n",
            "         0.1017],\n",
            "        [0.0969, 0.1034, 0.0989, 0.0975, 0.0982, 0.1057, 0.0994, 0.0980, 0.0998,\n",
            "         0.1024],\n",
            "        [0.0986, 0.1031, 0.1001, 0.0978, 0.0980, 0.1027, 0.0993, 0.0979, 0.1015,\n",
            "         0.1011]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0999, 0.1033, 0.0977, 0.0977, 0.0982, 0.1040, 0.0987, 0.0983, 0.1004,\n",
            "         0.1018],\n",
            "        [0.0975, 0.1036, 0.0970, 0.0936, 0.1013, 0.1062, 0.1022, 0.0948, 0.1023,\n",
            "         0.1015],\n",
            "        [0.0945, 0.1046, 0.0952, 0.0989, 0.1016, 0.1083, 0.0994, 0.0975, 0.0984,\n",
            "         0.1014],\n",
            "        [0.0976, 0.1032, 0.0967, 0.0969, 0.1020, 0.1054, 0.0985, 0.0974, 0.0991,\n",
            "         0.1033]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0970, 0.1031, 0.0991, 0.0961, 0.0992, 0.1058, 0.1001, 0.0990, 0.0990,\n",
            "         0.1016],\n",
            "        [0.0983, 0.1016, 0.0989, 0.0964, 0.0984, 0.1065, 0.0998, 0.0987, 0.0995,\n",
            "         0.1019],\n",
            "        [0.0971, 0.1005, 0.0990, 0.0969, 0.0997, 0.1062, 0.0975, 0.1007, 0.0990,\n",
            "         0.1034],\n",
            "        [0.0996, 0.1006, 0.0988, 0.0955, 0.1012, 0.1036, 0.0974, 0.0984, 0.1012,\n",
            "         0.1037]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0969, 0.1013, 0.0977, 0.0965, 0.1016, 0.1055, 0.1010, 0.0992, 0.0971,\n",
            "         0.1032],\n",
            "        [0.0967, 0.1045, 0.0987, 0.0989, 0.0988, 0.1064, 0.0972, 0.0961, 0.1010,\n",
            "         0.1017],\n",
            "        [0.0981, 0.1018, 0.0968, 0.0970, 0.0989, 0.1063, 0.1003, 0.0996, 0.1003,\n",
            "         0.1010],\n",
            "        [0.0968, 0.1054, 0.0980, 0.0976, 0.0978, 0.1061, 0.0987, 0.0982, 0.1000,\n",
            "         0.1014]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0982, 0.1017, 0.1002, 0.0961, 0.0981, 0.1057, 0.0998, 0.0976, 0.0998,\n",
            "         0.1028],\n",
            "        [0.1003, 0.1047, 0.0986, 0.0973, 0.0984, 0.1034, 0.1001, 0.0972, 0.0993,\n",
            "         0.1007],\n",
            "        [0.0979, 0.1025, 0.0960, 0.0971, 0.0990, 0.1065, 0.0965, 0.0991, 0.1003,\n",
            "         0.1050],\n",
            "        [0.0979, 0.1038, 0.0988, 0.0966, 0.0992, 0.1039, 0.0993, 0.0974, 0.1003,\n",
            "         0.1028]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0994, 0.1031, 0.0969, 0.0965, 0.0996, 0.1038, 0.0992, 0.0986, 0.0990,\n",
            "         0.1037],\n",
            "        [0.0987, 0.1019, 0.0981, 0.0974, 0.1006, 0.1040, 0.0982, 0.0982, 0.1005,\n",
            "         0.1025],\n",
            "        [0.0989, 0.1019, 0.0978, 0.0969, 0.0981, 0.1027, 0.1001, 0.1002, 0.1020,\n",
            "         0.1015],\n",
            "        [0.0947, 0.1034, 0.0997, 0.0972, 0.0973, 0.1085, 0.1002, 0.0979, 0.1001,\n",
            "         0.1009]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0991, 0.1028, 0.0943, 0.0959, 0.1004, 0.1039, 0.0980, 0.0985, 0.1019,\n",
            "         0.1054],\n",
            "        [0.0966, 0.1042, 0.0992, 0.0976, 0.0986, 0.1054, 0.0991, 0.0967, 0.0999,\n",
            "         0.1027],\n",
            "        [0.1000, 0.1025, 0.0969, 0.0981, 0.0972, 0.1043, 0.0983, 0.0982, 0.1016,\n",
            "         0.1029],\n",
            "        [0.0997, 0.1000, 0.0993, 0.0957, 0.0987, 0.1023, 0.1026, 0.0982, 0.1014,\n",
            "         0.1024]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
            "tensor([[0.0990, 0.1004, 0.1001, 0.0962, 0.0991, 0.1062, 0.0980, 0.0972, 0.1000,\n",
            "         0.1037],\n",
            "        [0.0989, 0.1003, 0.1003, 0.0968, 0.0982, 0.1045, 0.1006, 0.0994, 0.1004,\n",
            "         0.1004],\n",
            "        [0.0985, 0.1015, 0.1004, 0.0966, 0.1007, 0.1047, 0.0994, 0.0955, 0.1001,\n",
            "         0.1026],\n",
            "        [0.0969, 0.1068, 0.0976, 0.0946, 0.0983, 0.1053, 0.1002, 0.0955, 0.0997,\n",
            "         0.1051]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor([[0.0986, 0.1038, 0.0968, 0.0960, 0.0983, 0.1055, 0.0987, 0.0992, 0.1012,\n",
            "         0.1020],\n",
            "        [0.0999, 0.1017, 0.0984, 0.0960, 0.0993, 0.1056, 0.0986, 0.0990, 0.0989,\n",
            "         0.1025],\n",
            "        [0.0996, 0.1018, 0.0989, 0.0960, 0.0979, 0.1046, 0.0996, 0.0985, 0.1005,\n",
            "         0.1027],\n",
            "        [0.0965, 0.1032, 0.0976, 0.0953, 0.0997, 0.1072, 0.1008, 0.0983, 0.0978,\n",
            "         0.1037]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0985, 0.1021, 0.0985, 0.0972, 0.0996, 0.1056, 0.0980, 0.0982, 0.1001,\n",
            "         0.1023],\n",
            "        [0.0995, 0.1029, 0.0992, 0.0970, 0.1008, 0.1027, 0.1004, 0.0981, 0.0989,\n",
            "         0.1005],\n",
            "        [0.0969, 0.1019, 0.0993, 0.0975, 0.1013, 0.1022, 0.1005, 0.0990, 0.1006,\n",
            "         0.1007],\n",
            "        [0.0964, 0.1016, 0.0984, 0.0985, 0.0994, 0.1057, 0.0994, 0.0994, 0.0982,\n",
            "         0.1032]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0994, 0.1025, 0.0980, 0.0959, 0.0977, 0.1023, 0.1009, 0.0994, 0.1014,\n",
            "         0.1025],\n",
            "        [0.0953, 0.1024, 0.0970, 0.0974, 0.1019, 0.1040, 0.1002, 0.0986, 0.1007,\n",
            "         0.1025],\n",
            "        [0.0998, 0.1015, 0.0998, 0.0958, 0.0994, 0.1043, 0.0990, 0.0963, 0.1011,\n",
            "         0.1030],\n",
            "        [0.0968, 0.1079, 0.0930, 0.0984, 0.0993, 0.1054, 0.0994, 0.0950, 0.0994,\n",
            "         0.1054]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0966, 0.1022, 0.1007, 0.0983, 0.0992, 0.1065, 0.0993, 0.0967, 0.0980,\n",
            "         0.1023],\n",
            "        [0.0967, 0.1036, 0.0988, 0.0966, 0.1002, 0.1065, 0.0977, 0.0961, 0.0992,\n",
            "         0.1046],\n",
            "        [0.0993, 0.1030, 0.0986, 0.0970, 0.0982, 0.1036, 0.0992, 0.0985, 0.1011,\n",
            "         0.1015],\n",
            "        [0.0993, 0.1011, 0.0991, 0.0966, 0.0994, 0.1038, 0.0999, 0.1000, 0.0996,\n",
            "         0.1011]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0989, 0.1010, 0.0977, 0.0964, 0.0997, 0.1057, 0.0983, 0.0995, 0.0995,\n",
            "         0.1033],\n",
            "        [0.0988, 0.1018, 0.1001, 0.0964, 0.0981, 0.1045, 0.1007, 0.0986, 0.0991,\n",
            "         0.1019],\n",
            "        [0.0984, 0.1036, 0.0950, 0.0965, 0.1044, 0.1039, 0.0993, 0.0954, 0.1005,\n",
            "         0.1032],\n",
            "        [0.0978, 0.1033, 0.0991, 0.0965, 0.0993, 0.1043, 0.0996, 0.0975, 0.1010,\n",
            "         0.1016]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0981, 0.1017, 0.0976, 0.0963, 0.0996, 0.1057, 0.0987, 0.1010, 0.0979,\n",
            "         0.1034],\n",
            "        [0.0979, 0.1041, 0.0954, 0.0979, 0.1010, 0.1077, 0.1000, 0.0950, 0.1010,\n",
            "         0.1000],\n",
            "        [0.0990, 0.1018, 0.0991, 0.0971, 0.0984, 0.1046, 0.0993, 0.0984, 0.1001,\n",
            "         0.1021],\n",
            "        [0.0983, 0.1015, 0.0999, 0.0976, 0.1016, 0.1075, 0.1006, 0.0921, 0.0980,\n",
            "         0.1029]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0994, 0.1009, 0.1010, 0.0972, 0.0987, 0.1035, 0.0995, 0.0974, 0.1007,\n",
            "         0.1017],\n",
            "        [0.0957, 0.1060, 0.0947, 0.0984, 0.1028, 0.1052, 0.0990, 0.0971, 0.0981,\n",
            "         0.1029],\n",
            "        [0.0974, 0.1048, 0.0939, 0.0967, 0.1018, 0.1074, 0.0982, 0.0943, 0.1012,\n",
            "         0.1043],\n",
            "        [0.0984, 0.1010, 0.0999, 0.0961, 0.0995, 0.1057, 0.0995, 0.0985, 0.1004,\n",
            "         0.1010]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0985, 0.1018, 0.0994, 0.0959, 0.0971, 0.1048, 0.0997, 0.0993, 0.1002,\n",
            "         0.1033],\n",
            "        [0.0980, 0.1023, 0.0994, 0.0950, 0.1003, 0.1035, 0.0994, 0.0991, 0.1007,\n",
            "         0.1023],\n",
            "        [0.0971, 0.1019, 0.0979, 0.0985, 0.1000, 0.1054, 0.1006, 0.0991, 0.0989,\n",
            "         0.1007],\n",
            "        [0.0994, 0.1030, 0.0979, 0.0982, 0.0998, 0.1036, 0.0986, 0.0973, 0.1004,\n",
            "         0.1019]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0999, 0.1046, 0.0987, 0.0983, 0.0976, 0.1050, 0.1002, 0.0935, 0.0983,\n",
            "         0.1039],\n",
            "        [0.0982, 0.1028, 0.0982, 0.0968, 0.0992, 0.1046, 0.0987, 0.0994, 0.0987,\n",
            "         0.1034],\n",
            "        [0.0991, 0.1019, 0.0991, 0.0964, 0.0995, 0.1028, 0.1012, 0.0985, 0.1004,\n",
            "         0.1010],\n",
            "        [0.0979, 0.1012, 0.1004, 0.0968, 0.0989, 0.1045, 0.1015, 0.0968, 0.0992,\n",
            "         0.1028]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0974, 0.1018, 0.0989, 0.0987, 0.0994, 0.1084, 0.0990, 0.0970, 0.0996,\n",
            "         0.0998],\n",
            "        [0.0977, 0.1018, 0.1002, 0.0961, 0.0971, 0.1043, 0.0999, 0.0991, 0.1013,\n",
            "         0.1026],\n",
            "        [0.0966, 0.1012, 0.0982, 0.0957, 0.1044, 0.1059, 0.1005, 0.0962, 0.0999,\n",
            "         0.1013],\n",
            "        [0.0979, 0.1034, 0.0980, 0.0975, 0.0978, 0.1046, 0.0993, 0.0983, 0.1007,\n",
            "         0.1025]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0978, 0.1008, 0.0986, 0.0984, 0.0987, 0.1032, 0.0990, 0.1006, 0.1007,\n",
            "         0.1022],\n",
            "        [0.0980, 0.1027, 0.0990, 0.0974, 0.0985, 0.1036, 0.0990, 0.0991, 0.0998,\n",
            "         0.1029],\n",
            "        [0.0976, 0.1033, 0.0972, 0.0976, 0.0991, 0.1057, 0.0996, 0.0983, 0.0998,\n",
            "         0.1018],\n",
            "        [0.0985, 0.1016, 0.1000, 0.0969, 0.0981, 0.1046, 0.0997, 0.0988, 0.1002,\n",
            "         0.1016]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor([[0.0981, 0.1053, 0.0988, 0.0962, 0.0995, 0.1072, 0.0991, 0.0955, 0.0989,\n",
            "         0.1013],\n",
            "        [0.0980, 0.1029, 0.0962, 0.0979, 0.1025, 0.1048, 0.1006, 0.0985, 0.0982,\n",
            "         0.1003],\n",
            "        [0.0969, 0.1025, 0.0994, 0.0964, 0.0998, 0.1046, 0.1006, 0.0971, 0.1001,\n",
            "         0.1027],\n",
            "        [0.0988, 0.1000, 0.0982, 0.0968, 0.0991, 0.1044, 0.0997, 0.1003, 0.0989,\n",
            "         0.1037]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor([[0.0974, 0.1029, 0.0966, 0.0973, 0.1017, 0.1069, 0.1018, 0.0967, 0.0974,\n",
            "         0.1014],\n",
            "        [0.0970, 0.1009, 0.1001, 0.0959, 0.0984, 0.1050, 0.0994, 0.1001, 0.1005,\n",
            "         0.1026],\n",
            "        [0.0998, 0.1000, 0.0993, 0.0964, 0.1009, 0.1018, 0.1002, 0.0973, 0.1003,\n",
            "         0.1041],\n",
            "        [0.0961, 0.1028, 0.0971, 0.0986, 0.1003, 0.1050, 0.0981, 0.1004, 0.0996,\n",
            "         0.1020]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0974, 0.1025, 0.0994, 0.0969, 0.0996, 0.1059, 0.0996, 0.0980, 0.0969,\n",
            "         0.1038],\n",
            "        [0.0992, 0.1006, 0.0986, 0.0957, 0.0989, 0.1072, 0.1002, 0.0984, 0.0988,\n",
            "         0.1025],\n",
            "        [0.0965, 0.1015, 0.0955, 0.0981, 0.1038, 0.1046, 0.0984, 0.0955, 0.1042,\n",
            "         0.1020],\n",
            "        [0.0973, 0.1015, 0.0991, 0.0971, 0.0982, 0.1059, 0.0996, 0.0997, 0.1003,\n",
            "         0.1015]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0970, 0.1019, 0.0969, 0.0975, 0.1009, 0.1056, 0.0988, 0.0981, 0.1011,\n",
            "         0.1022],\n",
            "        [0.1003, 0.1021, 0.0979, 0.0966, 0.0975, 0.1049, 0.0996, 0.0989, 0.0993,\n",
            "         0.1029],\n",
            "        [0.0987, 0.1011, 0.0981, 0.0991, 0.0999, 0.1026, 0.1005, 0.0981, 0.1012,\n",
            "         0.1006],\n",
            "        [0.0984, 0.1007, 0.0990, 0.0979, 0.0991, 0.1038, 0.0993, 0.0998, 0.0999,\n",
            "         0.1021]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0948, 0.1025, 0.0985, 0.0971, 0.1012, 0.1055, 0.0998, 0.0986, 0.1005,\n",
            "         0.1013],\n",
            "        [0.0991, 0.0995, 0.0982, 0.0956, 0.0984, 0.1056, 0.1003, 0.0995, 0.1005,\n",
            "         0.1034],\n",
            "        [0.0976, 0.1023, 0.1004, 0.0963, 0.0984, 0.1051, 0.0998, 0.0988, 0.0995,\n",
            "         0.1018],\n",
            "        [0.0965, 0.1038, 0.0992, 0.0983, 0.0990, 0.1081, 0.0999, 0.0964, 0.0978,\n",
            "         0.1011]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0987, 0.1029, 0.0974, 0.0977, 0.0986, 0.1057, 0.0970, 0.0979, 0.1016,\n",
            "         0.1025],\n",
            "        [0.0988, 0.0995, 0.1003, 0.0962, 0.0980, 0.1040, 0.1000, 0.1001, 0.1005,\n",
            "         0.1025],\n",
            "        [0.0963, 0.1027, 0.0995, 0.0985, 0.0993, 0.1042, 0.1001, 0.0970, 0.1009,\n",
            "         0.1015],\n",
            "        [0.0983, 0.1015, 0.1003, 0.0961, 0.0998, 0.1028, 0.1009, 0.0987, 0.0993,\n",
            "         0.1022]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0974, 0.1022, 0.1001, 0.0967, 0.0987, 0.1068, 0.0966, 0.1004, 0.0991,\n",
            "         0.1020],\n",
            "        [0.0987, 0.1030, 0.0994, 0.0972, 0.0982, 0.1051, 0.0993, 0.0977, 0.0995,\n",
            "         0.1018],\n",
            "        [0.0991, 0.1018, 0.0973, 0.0971, 0.1003, 0.1051, 0.0992, 0.0985, 0.1009,\n",
            "         0.1008],\n",
            "        [0.0975, 0.1034, 0.0964, 0.0986, 0.0967, 0.1054, 0.1010, 0.0986, 0.1014,\n",
            "         0.1010]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0988, 0.1054, 0.0962, 0.0994, 0.1018, 0.1013, 0.0997, 0.0967, 0.0992,\n",
            "         0.1015],\n",
            "        [0.0963, 0.1065, 0.0981, 0.0987, 0.0977, 0.1064, 0.0977, 0.0976, 0.0983,\n",
            "         0.1026],\n",
            "        [0.0967, 0.1041, 0.0969, 0.0963, 0.1018, 0.1056, 0.1000, 0.0979, 0.0985,\n",
            "         0.1021],\n",
            "        [0.0985, 0.1018, 0.0989, 0.0975, 0.1000, 0.1038, 0.1001, 0.0960, 0.0999,\n",
            "         0.1034]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0968, 0.1025, 0.1000, 0.0973, 0.0983, 0.1058, 0.0991, 0.0981, 0.0998,\n",
            "         0.1024],\n",
            "        [0.1001, 0.1043, 0.0962, 0.0980, 0.1007, 0.1023, 0.1002, 0.0973, 0.0997,\n",
            "         0.1013],\n",
            "        [0.0985, 0.1055, 0.0967, 0.0970, 0.0982, 0.1051, 0.0998, 0.0940, 0.1021,\n",
            "         0.1031],\n",
            "        [0.0998, 0.1010, 0.0973, 0.0976, 0.0995, 0.1039, 0.0993, 0.0990, 0.1003,\n",
            "         0.1022]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor([[0.0962, 0.1014, 0.0988, 0.0977, 0.1010, 0.1063, 0.1008, 0.0960, 0.1004,\n",
            "         0.1015],\n",
            "        [0.0989, 0.1002, 0.0991, 0.0970, 0.1006, 0.1053, 0.0978, 0.0997, 0.0991,\n",
            "         0.1024],\n",
            "        [0.0995, 0.1021, 0.0986, 0.0973, 0.0991, 0.1041, 0.0999, 0.0980, 0.0988,\n",
            "         0.1027],\n",
            "        [0.0994, 0.1020, 0.1005, 0.0970, 0.0982, 0.1043, 0.1001, 0.0976, 0.1002,\n",
            "         0.1007]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[0.0972, 0.1015, 0.0994, 0.0968, 0.0991, 0.1054, 0.0989, 0.0982, 0.1019,\n",
            "         0.1016],\n",
            "        [0.0979, 0.1000, 0.0993, 0.0986, 0.0988, 0.1023, 0.1000, 0.0979, 0.1019,\n",
            "         0.1034],\n",
            "        [0.0990, 0.1076, 0.0933, 0.0962, 0.1017, 0.1074, 0.0991, 0.0932, 0.0984,\n",
            "         0.1042],\n",
            "        [0.0974, 0.1009, 0.0988, 0.0951, 0.0979, 0.1071, 0.0995, 0.0992, 0.1005,\n",
            "         0.1037]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0981, 0.1023, 0.0979, 0.0983, 0.0992, 0.1057, 0.0997, 0.0981, 0.0995,\n",
            "         0.1012],\n",
            "        [0.0973, 0.1017, 0.0977, 0.0965, 0.0974, 0.1052, 0.1006, 0.1000, 0.1019,\n",
            "         0.1017],\n",
            "        [0.0995, 0.1000, 0.0988, 0.0974, 0.0986, 0.1032, 0.0994, 0.1002, 0.1000,\n",
            "         0.1030],\n",
            "        [0.1016, 0.1008, 0.0954, 0.0976, 0.1001, 0.1008, 0.1016, 0.0961, 0.1010,\n",
            "         0.1048]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 10])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-383f437f0f62>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-8e599bdda768>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "fQfl3Sb5I-vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "id": "Z5jauxN_JAO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "aP2Z-X9hJBt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(images)"
      ],
      "metadata": {
        "id": "jrL0tnB4JDSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuIl99F1JEZ9",
        "outputId": "7ae51a4d-4d60-4382-fab2-3a9bad33d735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:  dog   car   dog   horse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEM4OodgJGJD",
        "outputId": "304255fe-f2e9-4e8a-fc50-bd62dce20157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 39 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQH9FthkJHSY",
        "outputId": "7e002aa8-d5e7-40bc-8da2-2d5e73de391e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class: plane is 51.7 %\n",
            "Accuracy for class: car   is 42.6 %\n",
            "Accuracy for class: bird  is 22.5 %\n",
            "Accuracy for class: cat   is 38.5 %\n",
            "Accuracy for class: deer  is 18.9 %\n",
            "Accuracy for class: dog   is 36.7 %\n",
            "Accuracy for class: frog  is 36.0 %\n",
            "Accuracy for class: horse is 60.2 %\n",
            "Accuracy for class: ship  is 40.3 %\n",
            "Accuracy for class: truck is 46.5 %\n"
          ]
        }
      ]
    }
  ]
}