{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqbWuLuDmCod",
        "outputId": "7d49e9b1-21e5-427e-a402-abfdfd03898d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gXHHzcwlmX1b",
        "outputId": "2d709eb9-c018-4fb0-b2aa-0e97bdc76a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "horse dog   car   plane\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "metadata": {
        "id": "KNBZqXkQmviY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(net, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GOnOA4hYHcP",
        "outputId": "bedd7b7b-24df-4761-b19d-f427ba0f3eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             456\n",
            "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
            "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
            "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
            "            Linear-5                  [-1, 120]          48,120\n",
            "            Linear-6                   [-1, 84]          10,164\n",
            "            Linear-7                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.06\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "ttQs0OpGm0Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        new_labels = [[0.0 for tt in range(10)] for t in range(4)]\n",
        "        for t in range(4):\n",
        "          new_labels[t][labels[t]] = 1.0\n",
        "        labels = torch.tensor(new_labels)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "83PaUU-ym7-E",
        "outputId": "c64cd412-9dae-45d8-8eab-37eb473b7ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-574275d5debe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgZ9sw0QokcZ",
        "outputId": "9216fedb-a9bc-4554-c469-a2ffc5f4cfae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 40 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnjzgj3govZ0",
        "outputId": "82ed4d4d-e25f-4263-e8ac-ee657e5797ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class: plane is 46.6 %\n",
            "Accuracy for class: car   is 50.7 %\n",
            "Accuracy for class: bird  is 15.7 %\n",
            "Accuracy for class: cat   is 12.5 %\n",
            "Accuracy for class: deer  is 19.9 %\n",
            "Accuracy for class: dog   is 35.3 %\n",
            "Accuracy for class: frog  is 61.3 %\n",
            "Accuracy for class: horse is 59.9 %\n",
            "Accuracy for class: ship  is 45.0 %\n",
            "Accuracy for class: truck is 58.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 데이터 전처리 및 데이터 로드\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# CIFAR-10 데이터셋 로드\n",
        "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# 데이터셋을 2x2 형태로 이어붙이기\n",
        "def concatenate_images(dataset):\n",
        "    concatenated_data = []\n",
        "    for i in range(0, len(dataset), 4):  # 4개씩 묶어서 이어붙이기\n",
        "        img1, _ = dataset[i]\n",
        "        img2, _ = dataset[i + 1]\n",
        "        img3, _ = dataset[i + 2]\n",
        "        img4, _ = dataset[i + 3]\n",
        "\n",
        "        concatenated_img = torch.cat([img1, img2, img3, img4], dim=2)\n",
        "        concatenated_data.append((concatenated_img, 0))  # 레이블은 임의로 0 지정\n",
        "\n",
        "    return concatenated_data\n",
        "\n",
        "concatenated_train_data = concatenate_images(cifar_train)\n",
        "\n",
        "# 이어붙인 데이터셋으로 DataLoader 생성\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(concatenated_train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 신경망 정의\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(16 * 16 * 16 * 4, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 16 * 16 * 16 * 4)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# 모델, 손실 함수, 최적화 함수 정의\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 훈련\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        '''print(outputs)\n",
        "        print(labels)\n",
        "        print(outputs.size())\n",
        "        print(labels.size())'''\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('훈련 완료')"
      ],
      "metadata": {
        "id": "pwHpv7iIo8E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# CIFAR-10 테스트 데이터셋 로드\n",
        "cifar_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 테스트 데이터셋을 2x2 형태로 이어붙이기\n",
        "def concatenate_images_test(dataset):\n",
        "    concatenated_data = []\n",
        "    for i in range(0, len(dataset), 4):  # 4개씩 묶어서 이어붙이기\n",
        "        img1, _ = dataset[i]\n",
        "        img2, _ = dataset[i + 1]\n",
        "        img3, _ = dataset[i + 2]\n",
        "        img4, _ = dataset[i + 3]\n",
        "\n",
        "        concatenated_img = torch.cat([img1, img2, img3, img4], dim=2)\n",
        "        concatenated_data.append((concatenated_img, 0))  # 클래스 인덱스는 여기서 중요하지 않습니다.\n",
        "\n",
        "    return concatenated_data\n",
        "\n",
        "concatenated_test_data = concatenate_images_test(cifar_test)\n",
        "\n",
        "# 이어붙인 테스트 데이터셋으로 DataLoader 생성\n",
        "batch_size = 64\n",
        "test_loader = DataLoader(concatenated_test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "fz4Qx09puRI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 데이터 전처리 및 데이터 로드\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# CIFAR-10 데이터셋 로드\n",
        "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# 데이터셋을 2x2 형태로 이어붙이기\n",
        "def concatenate_images(dataset):\n",
        "    concatenated_data = []\n",
        "    for i in range(0, len(dataset), 4):  # 4개씩 묶어서 이어붙이기\n",
        "        img1, _ = dataset[i]\n",
        "        img2, _ = dataset[i + 1]\n",
        "        img3, _ = dataset[i + 2]\n",
        "        img4, _ = dataset[i + 3]\n",
        "\n",
        "        concatenated_img = torch.cat([img1, img2, img3, img4], dim=2)\n",
        "        concatenated_data.append((concatenated_img, 1))  # 이진 분류를 위해 레이블을 1로 설정\n",
        "\n",
        "    return concatenated_data\n",
        "\n",
        "concatenated_train_data = concatenate_images(cifar_train)\n",
        "\n",
        "# 이어붙인 데이터셋으로 DataLoader 생성\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(concatenated_train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 신경망 정의\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(16 * 16 * 16, 1)  # 이진 분류를 위해 출력 크기를 1로 수정\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 16 * 16 * 16)\n",
        "        x = self.fc1(x)\n",
        "        x = self.sigmoid(x)  # Sigmoid 함수 적용\n",
        "        return x\n",
        "\n",
        "# 모델, 손실 함수, 최적화 함수 정의\n",
        "model = SimpleCNN()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 훈련\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))  # BCEWithLogitsLoss를 사용하므로 레이블을 float로 변환\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('훈련 완료')\n",
        "\n",
        "# 테스트\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in train_loader:\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs > 0.5).float()  # 0.5를 기준으로 이진 분류\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.float().view(-1, 1)).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "QucIpWvRwp1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "vgg = models.vgg16()\n",
        "summary(model.vgg16(), (3, 32, 32))\n"
      ],
      "metadata": {
        "id": "Hh6Fz9pMxPXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "RNUjDhcT2m34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13facf57-873f-49f8-bc0c-782a8a28e83b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch\n",
            "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchgen"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install saver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL7E4HOR1hM-",
        "outputId": "6cc37f72-ed35-4330-a858-55860421603b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting saver\n",
            "  Downloading saver-0.0.2-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: saver\n",
            "Successfully installed saver-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeMLS_iN3BSY",
        "outputId": "4cf02cb4-54f4-4560-cd1e-767244db86e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: utils\n",
            "Version: 1.0.1\n",
            "Summary: A grab-bag of utility functions and objects\n",
            "Home-page: http://github.com/haaksmash/pyutils\n",
            "Author: Haak Saxberg\n",
            "Author-email: haak.erling@gmail.com\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip list"
      ],
      "metadata": {
        "id": "QW67s4S13gi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install data"
      ],
      "metadata": {
        "id": "JYgfo1Z71snb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b6661f-3242-4bf9-e12f-67a247c2b1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: data in /usr/local/lib/python3.10/dist-packages (0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from data) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from data) (4.4.2)\n",
            "Requirement already satisfied: funcsigs in /usr/local/lib/python3.10/dist-packages (from data) (1.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/zshicode/GNN-for-text-classification.git\n",
        "%cd GNN-for-text-classification/\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e98LrWs24CO3",
        "outputId": "b632d6f6-d10a-4472-ea9f-740406a8f729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GNN-for-text-classification'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 36 (delta 3), reused 31 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (36/36), 1.52 MiB | 8.16 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/GNN-for-text-classification\n",
            "config.py  \u001b[0m\u001b[01;34mdata\u001b[0m/  main.py  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mpreprocess\u001b[0m/  README.md  \u001b[01;34mresult\u001b[0m/  \u001b[01;34mutils\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('./GNN-for-text-classification/')"
      ],
      "metadata": {
        "id": "0UAQ1GZ84zMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchvision\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch import nn\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Data\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "train_trans = transforms.Compose([transforms.Resize(321),\n",
        "                                  transforms.RandomCrop(224),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  normalize,\n",
        "                                  ])\n",
        "val_trans = transforms.Compose([transforms.Resize(321),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                normalize,\n",
        "                                ])\n",
        "# CIFAR-10 데이터셋 로드\n",
        "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_trans)\n",
        "\n",
        "# 데이터셋을 2x2 형태로 이어붙이기\n",
        "def concatenate_images(dataset):\n",
        "    concatenated_data = []\n",
        "    for i in range(0, len(dataset), 4):  # 4개씩 묶어서 이어붙이기\n",
        "        img1, _ = dataset[i]\n",
        "        img2, _ = dataset[i + 1]\n",
        "        img3, _ = dataset[i + 2]\n",
        "        img4, _ = dataset[i + 3]\n",
        "\n",
        "        concatenated_img = torch.cat([img1, img2, img3, img4], dim=2)\n",
        "        concatenated_data.append((concatenated_img, 0))  # 레이블은 임의로 0 지정\n",
        "\n",
        "    return concatenated_data\n",
        "\n",
        "train_ds = concatenate_images(cifar_train)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, drop_last=True)\n",
        "cifar_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_trans)\n",
        "\n",
        "# 테스트 데이터셋을 2x2 형태로 이어붙이기\n",
        "def concatenate_images_test(dataset):\n",
        "    concatenated_data = []\n",
        "    for i in range(0, len(dataset), 4):  # 4개씩 묶어서 이어붙이기\n",
        "        img1, _ = dataset[i]\n",
        "        img2, _ = dataset[i + 1]\n",
        "        img3, _ = dataset[i + 2]\n",
        "        img4, _ = dataset[i + 3]\n",
        "\n",
        "        concatenated_img = torch.cat([img1, img2, img3, img4], dim=2)\n",
        "        concatenated_data.append((concatenated_img, 0))  # 클래스 인덱스는 여기서 중요하지 않습니다.\n",
        "\n",
        "    return concatenated_data\n",
        "\n",
        "val_ds = concatenate_images_test(cifar_test)\n",
        "\n",
        "# 이어붙인 테스트 데이터셋으로 DataLoader 생성\n",
        "val_dl = DataLoader(val_ds, batch_size=8, shuffle=False)\n",
        "\n",
        "# Model\n",
        "model = vgg19(pretrained=True)\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_ftrs, train_ds.CLASSES)\n",
        "model = model\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 20, gamma=0.2)\n",
        "best_pred = 0\n",
        "\n",
        "for epoch in range(11):\n",
        "    model.train()\n",
        "    scheduler.step()\n",
        "\n",
        "    iterator = tqdm(train_dl)\n",
        "    for batch_idx, (image, labels) in enumerate(iterator):\n",
        "        image = image\n",
        "        labels = labels\n",
        "\n",
        "        predictions = model(image)\n",
        "\n",
        "        loss = criterion(predictions, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterator.set_description(\n",
        "            'Epoch [{epoch}/{epochs}] :: Loss {loss:.4f}'.format(epoch=epoch + 1, epochs=1000, loss=loss.item()))\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "\n",
        "        iterator = tqdm(val_dl)\n",
        "\n",
        "        for batch_idx, (image, labels) in enumerate(iterator):\n",
        "            image = image\n",
        "            labels = labels\n",
        "\n",
        "            predictions = model(image)\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            # Mulit GPU handling\n",
        "            if type(predictions) is list:\n",
        "                predictions = torch.cat(predictions)\n",
        "            pred_soft = torch.sigmoid(predictions)\n",
        "            pred_binary = pred_soft.gt(0.5).type(predictions.type())\n",
        "\n",
        "            iterator.set_description(\n",
        "                'Val :: Loss {loss:.4f}'.format(loss=loss.item()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "4QsN1tWWx_In",
        "outputId": "8dca493c-fe9f-4e49-b6c6-85f3649ebdff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e89a0cbb15b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodulefinder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mraise\u001b[0m  \u001b[0;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchvision\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch import nn\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Data\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "train_trans = transforms.Compose([transforms.Resize(321),\n",
        "                                  transforms.RandomCrop(224),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  normalize,\n",
        "                                  ])\n",
        "val_trans = transforms.Compose([transforms.Resize(321),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                normalize,\n",
        "                                ])\n",
        "# CIFAR-10 데이터셋 로드\n",
        "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_trans)\n",
        "\n",
        "# 데이터셋을 2x2 형태로 이어붙이기\n",
        "def concatenate_images(dataset):\n",
        "    concatenated_data = []\n",
        "    for i in range(0, len(dataset), 4):  # 4개씩 묶어서 이어붙이기\n",
        "        img1, _ = dataset[i]\n",
        "        img2, _ = dataset[i + 1]\n",
        "        img3, _ = dataset[i + 2]\n",
        "        img4, _ = dataset[i + 3]\n",
        "\n",
        "        concatenated_img = torch.cat([img1, img2, img3, img4], dim=2)\n",
        "        concatenated_data.append((concatenated_img, 0))  # 레이블은 임의로 0 지정\n",
        "\n",
        "    return concatenated_data\n",
        "\n",
        "train_ds = concatenate_images(cifar_train)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, drop_last=True)\n",
        "cifar_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_trans)\n",
        "\n",
        "# 테스트 데이터셋을 2x2 형태로 이어붙이기\n",
        "def concatenate_images_test(dataset):\n",
        "    concatenated_data = []\n",
        "    for i in range(0, len(dataset), 4):  # 4개씩 묶어서 이어붙이기\n",
        "        img1, _ = dataset[i]\n",
        "        img2, _ = dataset[i + 1]\n",
        "        img3, _ = dataset[i + 2]\n",
        "        img4, _ = dataset[i + 3]\n",
        "\n",
        "        concatenated_img = torch.cat([img1, img2, img3, img4], dim=2)\n",
        "        concatenated_data.append((concatenated_img, 0))  # 클래스 인덱스는 여기서 중요하지 않습니다.\n",
        "\n",
        "    return concatenated_data\n",
        "\n",
        "val_ds = concatenate_images_test(cifar_test)\n",
        "\n",
        "# 이어붙인 테스트 데이터셋으로 DataLoader 생성\n",
        "val_dl = DataLoader(val_ds, batch_size=8, shuffle=False)\n",
        "\n",
        "# Model\n",
        "model = vgg19(pretrained=True)\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_ftrs, train_ds.CLASSES)\n",
        "model = model\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 20, gamma=0.2)\n",
        "best_pred = 0\n",
        "\n",
        "for epoch in range(11):\n",
        "    model.train()\n",
        "    scheduler.step()\n",
        "\n",
        "    iterator = tqdm(train_dl)\n",
        "    for batch_idx, (image, labels) in enumerate(iterator):\n",
        "        image = image\n",
        "        labels = labels\n",
        "\n",
        "        predictions = model(image)\n",
        "\n",
        "        loss = criterion(predictions, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        iterator.set_description(\n",
        "            'Epoch [{epoch}/{epochs}] :: Loss {loss:.4f}'.format(epoch=epoch + 1, epochs=1000, loss=loss.item()))\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "\n",
        "        iterator = tqdm(val_dl)\n",
        "\n",
        "        for batch_idx, (image, labels) in enumerate(iterator):\n",
        "            image = image\n",
        "            labels = labels\n",
        "\n",
        "            predictions = model(image)\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            # Mulit GPU handling\n",
        "            if type(predictions) is list:\n",
        "                predictions = torch.cat(predictions)\n",
        "            pred_soft = torch.sigmoid(predictions)\n",
        "            pred_binary = pred_soft.gt(0.5).type(predictions.type())\n",
        "\n",
        "            iterator.set_description(\n",
        "                'Val :: Loss {loss:.4f}'.format(loss=loss.item()))\n",
        "\n"
      ],
      "metadata": {
        "id": "uxRjoqLmDjuS",
        "outputId": "197a5e01-b9bd-4fd2-e7ab-dbc02fe8f020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e89a0cbb15b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodulefinder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mraise\u001b[0m  \u001b[0;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
          ]
        }
      ]
    }
  ]
}